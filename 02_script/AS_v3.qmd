---
title: "Análise de sequência"
format: html
editor: visual
---

# 1. Análise de sequência

A análise de sequência contém três etapas principais:

1.  Codificação das narrativas ou processos em sequências;

2.  Mensuração das dissimilaridades dos indivíduos par a par ;

3.  Aplicação de técnica de redução de dimensionalidade (ex.: análise de cluster) para agrupar sequências similares.

Antes de adentrar nestas etapas, vamos trabalhar com o tratamento dos dados conforme script a seguir.

## 1.1. Tratamento dos dados (2023-2024)

A base de dados utilizada neste script, é a de trabalhadores que participaram de pelo menos cinco entrevistas em cinco trimestres seguidos, e que foram TCP em algum momento.

Carregando pacotes necessários.

```{r}
#| message: false
#| warning: false
#| paged-print: false

options(scipen = 999)

library(TraMineR)
library(tidyverse)
library(TraMineRextras)
library(FactoMineR)
library(questionr)
library(descriptio)
library(purrr)
library(stringr)
library(ggseqplot)
library(factoextra)
library(readxl)
library(survey)
library(cluster)
library(NbClust)
library(nnet)
library(geojsonio)
library(geobr)
library(ggspatial)
library(sf)
library(writexl)

```

A seguir é selecionada as variáveis que serão importantes para análises e definida a variável *Trimestre_Ano*.

```{r}
#| message: false
#| warning: false
#| paged-print: false

data_0 <- read_csv("C:/Users/alefs/OneDrive/Documentos/LAPEI-CIGETS/GitHub/tcp/as_2023_2024_v4.csv") |> 
  rename(pessoas_domicilio = n)

data_1 <- data_0 |>   
        select(id, Ano, Trimestre, UF, 
               UPA, Estrato, 
               V1008,V4012,V1014,V1022,
               V1016, V2007, V2008, V20081, 
               V20082, V2009,
               VD4001,VD4002, VD3004, V4039,
               VD4010, V4032, V4019, V2010,
               V2005, VD4016, V1028, pessoas_domicilio,
               VD4016_ajust) |>  
  mutate(Trimestre_Ano = paste(Trimestre, 
                           Ano, sep = "-"), 
                           .before = UF)
```

O objeto de análise é a categoria de ocupação (V4012). Para isso serão necessárias algumas adaptações. A primeira é reduzir o número de categorias considerando a natureza delas e com fins de simplificação de análise. A tabela abaixo sintetiza as transformações realizadas.

+-----------------------------------------------+-------------------------------+--------------+
| Antes do tratamento                           | Após o tratamento             | Abreviação   |
+===============================================+:=============================:+:============:+
| -   Empregado do setor privado. (V4012)       | Empregado do setor privado    | ESPR         |
|                                               |                               |              |
| -   Trabalhador doméstico. (V4012)            |                               |              |
+-----------------------------------------------+-------------------------------+--------------+
| -   Pessoa fora da força de tratalho (VD4001) | Fora do trabalho              | PFT          |
|                                               |                               |              |
| -   Pessoa desocupada (VD4002)                |                               |              |
+-----------------------------------------------+-------------------------------+--------------+
| -   Conta própria. (V4012)                    | Trabalhador por conta própria | TCP          |
+-----------------------------------------------+-------------------------------+--------------+
| -   Empregado do setor público                | Empregado do setor público    | ESPub        |
|                                               |                               |              |
| -   Militar                                   |                               |              |
+-----------------------------------------------+-------------------------------+--------------+
| -   Empregador                                | Empregador                    | EMP          |
+-----------------------------------------------+-------------------------------+--------------+

```{r}

data_2 <- data_1 |> 
  mutate(V4012_ajust = 
           case_when(
                V4012 == "Conta própria"  ~ "TCP",
                V4012 == "Empregado do setor privado" ~ "ESPriv",
                V4012 == "Trabalhador doméstico" ~ "ESPriv",
                V4012 == "Empregado do setor público (inclusive empresas de economia mista)" ~ "ESPub",
                V4012 == "Militar do exército, da marinha, da aeronáutica, da polícia militar ou do corpo de bombeiros militar" ~ "ESPub",  
                V4012 == "Trabalhador familiar não remunerado" ~ "TFNR",
                V4012 == "Empregador" ~ "EMP"), 
         .after = Ano) |> 
  mutate(
      ocupacao = 
        case_when(
                VD4001 == "Pessoas na força de trabalho" & 
                VD4002 == "Pessoas ocupadas" ~ 
                                  as.character(V4012_ajust),
                VD4001 == "Pessoas na força de trabalho" & 
                VD4002 == "Pessoas desocupadas" ~ "PFT",
                VD4001 == "Pessoas fora da força de trabalho" ~ 
                                  "PFT"), 
      .after = V4012_ajust)

data_2 |> 
  distinct(id) |>
  count()
```

Foram identificados 53.384 indivíduos. Pelo fato da ocupação trabalhador familiar não remunerado ser pouco frequente entre os indivíduos e para diminuir a complexidade da análise, optamos por removê-los do estudo, além de empregados do setor público. Também serão removidos aqueles que ainda não haviam completados 14 anos de idade na primeira entrevista e os que haviam atingido mais de 65 na última.

```{r}


tfnr <- data_2 |> 
          filter(ocupacao == "TFNR") |> 
  distinct(id)
tfnr <- tfnr$id

espub <- data_2 |> 
          filter(ocupacao == "ESPub") |> 
  distinct(id)
espub <- espub$id

emp <- data_2 |> 
          filter(ocupacao == "EMP") |> 
  distinct(id)
emp <- emp$id

menor_idade <- data_2 |> 
  filter(V1016 == 1 & V2009 < 15)
menor_idade <- menor_idade$id

maior_idade <- data_2 |> 
  filter(V1016 == 5 & V2009 > 64)
maior_idade <- maior_idade$id

dados_tratados <- data_2 |> 
            filter(!id %in% tfnr) |> 
            filter(!id %in% espub) |> 
            filter(!id %in% menor_idade) |> 
            filter(!id %in% maior_idade) |> 
            filter(!id %in% emp)

dados_tratados |> 
  distinct(id) |>
  count()
```

No próximo bloco, serão selecionadas as variáveis de interesse:

-   id: identificação do indivíduo;

-   V1016: número da entrevista (de 1 a 5)

-   ocupação: categoria ocupacional.

A partir da próxima subseção começamos a lidar com a análise de sequência propriamente dita.

## 1.2. Codificação das narrativas ou processos em sequências

Nesta etapa, os processos são codificados em sequências. Precisamos deixar os dados em um formato para rodar a análise de sequências.

```{r}

data_long <- 
  dados_tratados |>
  select(id, V1016,ocupacao)

#Transformando a estrutura de dados para wide
data_wide <- data_long |> 
  pivot_wider(names_from = V1016, 
              values_from = ocupacao,
              values_fn = list)

# Colocando as colunas em ordem de entrevista e para caracteres
data_ordem <- data_wide|> 
  relocate(id,`1`, `2`, `3`, `4`, `5`) |>
  mutate(across(`1`:`5`, as.character)) 

# id_seq foi criada apenas para ter mais uma coluna de identificação 

data_filtro <- data_ordem  |> 
  filter(if_all(2:6, ~ . != "NULL")) |>  
  filter(rowSums(across(2:6, ~ . != "TCP")) < 5) |> 
  mutate(id_seq = row_number())

```

### 1.2.1. Separando amostras aleatórias para alguns testes

O conjunto de dados é muito amplo, o que tem inviabilizado, devido à limitações computacionais, rodar a técnica para toda a base. Para superar tal limitação, trabalhamos com uma amostra de 5000 observações extraídas aleatoriamente da base original. Esta limitação acaba abrindo uma possibilidade que é viabilizar avaliações de outras amostragens para validar se os tipos de sequências se mantém.

Geraremos três amostras aleatórios de 6.000 observações para testar os diferentes métodos de clusterização. A primeira amostra será usada para "treinar" e a segunda e terceira amostras serão aplicadas para "testar".

```{r}
set.seed(123)

num_amostras <- 3
tamanho_amostra <- 6000

lista_amostras <- data_filtro |> 
  slice_sample(n = num_amostras*tamanho_amostra, replace = FALSE) |> 
  mutate(grupo_amostra = rep(1:num_amostras, each = tamanho_amostra)) |> 
  group_split(grupo_amostra, .keep = FALSE)

amostra1 <- lista_amostras[[1]]
amostra2 <- lista_amostras[[2]]
amostra3 <- lista_amostras[[3]]
```

### 1.2.2. Análise exploratória de sequências

Aqui observaremos algumas análises exploratórias sobre a sequência da amostra 1.

```{r}
#|warning: FALSE
# Objeto de sequência

rownames(amostra1) <- amostra1$id_seq

#cores_personalizadas <- c(
#  "EMP"    = "#1F78B4",
#  "ESPriv" = "#FDBF00",
#  "ESPub"  = "#A65628", 
#  "PFT"    = "#E34A33",
#  "TCP"    = "#33A02C"
#)

cores_personalizadas <- c(
  "ESPriv" = "#FDBF00",
  "PFT"    = "#E34A33",
  "TCP"    = "#33A02C"
)




seq <- seqdef(amostra1,
              var = 2:6,
              id = amostra1[[7]],
              cnames = c("1", "2", "3", "4", "5"),
              cpal = cores_personalizadas
              )

# este objeto abaixo serve para juntar às bases originais 

base_join <- cbind(seq, 
                   amostra1$id_seq, 
                   amostra1$id) |> 
              rename(id_seq_original = `amostra1$id_seq`,
                     id = `amostra1$id`) |> 
              mutate(id_pos_seq = row_number())
```

O número de sequências possíveis, considerando 5 períodos no tempo e três estados possíveis são: 243. A partir da amostragem selecionada, foram encontradas 208 sequências únicas.

```{r}
seqtab(seq, idx=0) |> 
  nrow()
```

Pelo gráfico de estado abaixo, observa-se a prevalência de TCP em todos os períodos.

```{r}
# Gráfico de estado
seqdplot(seq, 
         xtlab=1:5, 
         cex.legend=0.9, 
         main = "Gráfico de estados",
         with.legend = "right")
```

O gráfico de índices mostra as 6.000 sequências. Todavia, a visualização é prejudicada devido ao número de observações.

```{r}
# Gráfico de índices
seqIplot(seq, 
         main = "Gráficos de índices", 
         with.legend = "right")
```

Para superar tal limitação, separamos as 10 sequências mais prevalentes.

```{r}
# As dez mais frequentes

seqfplot(seq, 
         main="Dez mais frequentes", 
         with.legend = "right")

```

A matriz de transição, apresentada abaixo, mostra a frequência de transição de um estado a outro, do momento t~0~ ao momento t~1~.

Observação, com base no eixo diagonal, que geralmente quem está uma categoria tende a permanecer na mesma categoria no momento posterior. Este fato é sobretudo válido para o TCP.

```{r}
ggseqtrplot(seq, 
            dss = FALSE) +
  ggtitle("Gráfico de transição")
```

## 1.3. Mensuração das dissimilaridades de par a par de indivíduos

Para gerar agrupamentos, primeiramente definiremos a matriz de dissimilaridades através da função seqdist, usando método Optimal Matching (OM).

```{r}
#|warning: false

# Definindo a matriz de dissimilaridades

couts <- seqsubm(seq, 
                 method="CONSTANT", 
                 cval=2)

dissim <- seqdist(seq, 
                  method="OM", 
                  sm=couts, 
                  indel=1.5,
                  full.matrix = TRUE)
```

## 1.4. Aplicação de técnica de redução de dimensionalidade para agrupar sequências similares

O próximo passo consiste na aplicação da técnica de clusterização. Existem diversas técnicas e procedimentos que podem ser usados. Para nosso caso, aplicamos uma clusterização pelo método de k-means.

Antes de iniciar a clusterização, aplicamos a técnica de principal components analysis para reduzir o número de atributos em apenas duas dimensões. Isso é útil para visualizar os clusters, depois de formados, em duas dimensões.

É possível fazer a clusterização sem a PCA? Sim, aplicamos e o resultado não foi muito diferente. Então vamos manter a PCA, especialmente por facilitar a visualização em duas dimensões e por aprimorar o desempenho do processamento da clusterização.

```{r}
# aplicando PCA
mds <- cmdscale(dissim, k=2)  # Redução para 2 dimensões

mds_df_kmeans <- as.data.frame(mds)

colnames(mds_df_kmeans) <- c("Dim1", 
                             "Dim2")
```

Não existe clareza sobre o melhor número de clusters. De acordo com o elbow plot seria 3 clusters.

```{r}
scree_plot <- fviz_nbclust(mds_df_kmeans, 
             kmeans, 
             k.max = 7,
             method = "wss")

#nc <- NbClust(mds_df_kmeans,
 #             diss = dissim,
  #            min.nc = 2,
   #           max.nc = 7,
    #          method = "kmeans",
     #         distance = NULL,
      #        index = "all")

ggsave(plot = scree_plot, "scree_plot.png", width = 8, height =  6)
```

```{r}
numero_clusters <- nc[["All.index"]]
```

### 1.4.1. Testando com três clusters

Agora vamos testar a clusterização dividindo a amostra em três grupos.

```{r}

set.seed(123) 
mds_df_kmeans$sequencia_id <- 1:nrow(mds_df_kmeans)


kmeans_result <- kmeans(mds_df_kmeans[, c("Dim1", "Dim2")], 
                        centers=3) 

# 5. Adicione os resultados do cluster ao data frame
mds_df_kmeans$cluster <- as.factor(kmeans_result$cluster)


ggplot(mds_df_kmeans, aes(x=Dim1, 
                          y=Dim2, 
                          color=cluster)) +
  geom_point(size=3) +
  geom_label(aes(label=sequencia_id), 
             vjust=-1, 
             hjust=0.5, 
             size=3) +  
  labs(title="Gráfico de Dispersão com 3 Clusters", 
       x="Dimensão 1", 
       y="Dimensão 2") +
  theme_minimal()

```

```{r}
indice_cluster <- seqIplot(seq, 
    group = kmeans_result$cluster,
    border = NA, 
    ylab = c("3.300 seq.", "1.448 seq.", "1.252 seq."),
    ltext = c("Empregado do setor privado", "Pessoa sem trabalho", "Trabalhador por conta própria"),
    yaxis = FALSE,
    cex.legend = 1.3,
    use.layout = TRUE,
    legend.prop = 0.15,
    main = c("Persistentes", "Necessidade", "Intermitentes"))

```

```{r}
png("indice_cluster.png", width = 1500, height = 1200, res = 200) # largura, altura e resolução
seqIplot(seq, 
    group = kmeans_result$cluster,
    border = NA, 
    ylab = c("3.300 seq. (55%)", "1.448 seq. (24%)", "1.252 seq. (21%)"),
    ltext = c("Empregado do setor privado", "Pessoa sem trabalho", "Trabalhador por conta própria"),
    yaxis = FALSE,
    cex.legend = 1.2,
    use.layout = TRUE,
    legend.prop = 0.15,
    main = c("Persistentes", "Necessidade", "Intermitentes"))
dev.off() # fecha o dispositivo gráfico
```

### 1.4.3. Juntando base original aos clusters

```{r}

base_cluster <- cbind(seq, 
                   amostra1$id_seq, 
                   amostra1$id,
                   mds_df_kmeans$cluster) %>%
  rename(id_sequenciamento = `amostra1$id_seq`,
         id = `amostra1$id`,
         cluster = `mds_df_kmeans$cluster`)  |> 
  mutate(cluster = as.character(cluster),
         cluster = case_when(cluster == "1" ~ "Persistente",
                              cluster == "2" ~ "Precarizado",
                              cluster == "3" ~ "Transitório"))
  
id_cluster <- base_cluster |> 
  distinct(id, cluster)

renda <- dados_tratados |> 
  filter(id %in% id_cluster$id) |> 
  filter(ocupacao == "TCP") |> 
  group_by(id) |> 
  summarise(renda_media = mean(VD4016_ajust))

dados_cluster <- dados_tratados |> 
  filter(id %in% id_cluster$id) |> 
  left_join(id_cluster, by = "id") |> 
  relocate(cluster, .after = ocupacao) |> 
  filter(V1016 == 3) |> 
  mutate(regiao = case_when(
    UF %in% c("Rondônia", "Acre", "Amazonas", "Roraima", "Pará", "Amapá", "Tocantins") ~ "Norte",
    UF %in% c("Maranhão", "Piauí", "Ceará", "Rio Grande do Norte", "Paraíba", "Pernambuco", "Alagoas", "Sergipe", "Bahia") ~ "Nordeste",
    UF %in% c("Minas Gerais", "Espírito Santo", "Rio de Janeiro", "São Paulo") ~ "Sudeste",
    UF %in% c("Paraná", "Santa Catarina", "Rio Grande do Sul") ~ "Sul",
    UF %in% c("Mato Grosso do Sul", "Mato Grosso", "Goiás", "Distrito Federal") ~ "Centro-Oeste",
    TRUE ~ NA_character_
  )) |> 
  mutate(Persistente = as.numeric(cluster == "Persistente"),
         Precarizado = as.numeric(cluster == "Precarizado"),
         Transitório = as.numeric(cluster == "Transitório")) |> 
  mutate(chefe_domicilio = if_else(V2005 == "Pessoa responsável pelo domicílio", "Responsável pelo domicílio", "Não responsável pelo domicílio")) |> 
  mutate(VD4010 = if_else(is.na(VD4010), "Desocupado", VD4010)) |> 
  mutate(ensino_superior = if_else(VD3004 == "Superior completo", "Superior completo", "Sem superior completo")) |> 
  left_join(renda, by = "id")
```

## 1.5. Análise descritiva dos clusters.

A PnadC por se tratar de uma pesquisa de amostragem complexa, é necessário pesos populacionais nas análises descritivas e inferenciais, no qual é representada pela variável V1028, que calibra pelas projeções populacionais. Essa variável indica quantas pessoas existem com as mesmas características daquela amostra/indivíduo. As função da biblioteca `survey`, são indicadas para incoporar os referidos pesos nas análises pretendidas. No entanto, também é possível realizar isso de forma mais rudimentar, usando as funções do `tidyverse`, tendo V1028 como peso. Para fins didáticos e para futuras consultas, testaremos ambas as técnicas.

### 1.5.1. UF

O bloco abaixo mostra como agregar o peso amostral utilizando as funções do `tidyverse`.

```{r}

descritivo_uf <- dados_cluster |> 
  count(UF, cluster, wt = V1028) |> 
  pivot_wider(names_from = cluster, values_from = n) |> 
  mutate(
    perc_Persistente = Persistente / (Persistente + Precarizado + Transitório),
    perc_Precarizado = Precarizado / (Persistente + Precarizado + Transitório),
    perc_Transitório = Transitório / (Persistente + Precarizado + Transitório)
  ) |> 
  select(-Persistente, -Precarizado, -Transitório) |> 
  arrange(-perc_Persistente)
    
descritivo_uf
```

Abaixo, consideramos o peso amostral através da função `svydesign` da bilioteca `survey` , para utilizarmos nas demais funções do pacote.

```{r}
design <- svydesign(ids = ~UPA, weights = ~V1028, data = dados_cluster)

```

A função `svyby` é utilizada para calcular proporções de variáveis categóricas, agregando o objeto design que modela o peso populacional.

```{r}


descritivo_uf_2 <- svyby(~Persistente + Precarizado + Transitório, ~UF, design, svymean) |> 
  select(Persistente, Precarizado, Transitório) |> 
  arrange(-Persistente)

descritivo_uf_2
```

Como observado, os resultados através das duas técnicas são os mesmos. De acordo com os resultados, os dos maiores percentuais por cluster são:

-   **Persistente**: Rio Grande do Sul e Amapá.

-   **Precarizado:** Maranhão e Ceará.

-   **Transitório**: Paraná e Distrito Federal.

```{r}
descritivo_uf_long <- descritivo_uf |> 
  pivot_longer(
    cols = 2:4,
    names_to = "Categoria",
    values_to = "Proporcao") |> 
  mutate(Categoria = recode(Categoria,
    "perc_Persistente" = "Persistente",
    "perc_Transitório" = "Intermitente",
    "perc_Precarizado" = "Necessidade"
  ))


grafico_uf <- descritivo_uf_long |> 
  ggplot(aes(x = reorder(UF, (Proporcao * (Categoria == "Persistente")), FUN = sum),
             y = Proporcao,
             fill = Categoria)) +
  geom_bar(stat = "identity",
           position = "fill",
           width = 0.8,
           color = "white",
           alpha = 0.8) +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    x = NULL,
    y = NULL,
    fill = NULL
  ) +
  geom_text(aes(label = scales::percent(Proporcao, accuracy = 1)),
            position = position_fill(vjust = 0.5),
            size = 4.5,
            color = "white") +
  scale_fill_manual(
    values = c(
      "Persistente" = "#33A02C",
      "Necessidade" = "#E34A33",
      "Intermitente" = "#FDBF00")) +
  theme_minimal() +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_text(size = 14),
        legend.position = "top",
        legend.text = element_text(size = 14))

ggsave(plot = grafico_uf, filename = "grafico_uf.png", height = 1000, width = 1500, units = "px", dpi = 150)
```

Nas próximas análises seguiremos adotando as funções do pacote `survey`.

### 1.5.2. Região

```{r}
descritivo_regiao <- svyby(~Persistente + Precarizado + Transitório, ~regiao, design, svymean) |> 
  select(Persistente, Precarizado, Transitório) |> 
  arrange(-Persistente)

descritivo_regiao
```

Ao analisar por região, temos que o Sul é que têm o maior percentual de persistentes. Enquanto o Nordeste e Centro-Oeste concentram os maiores números de, respectivamente, Precarizados e Transitórios.

### 1.5.3. Situação do domicílio

```{r}
descritivo_urbanidade <- svyby(~V1022, ~cluster, design, svymean) |> 
  select(V1022Rural, V1022Urbana)
descritivo_urbanidade

#urbanidade_2 <- svyby(~Persistente + Precarizado + Transitório, ~V1022, design, svymean) |> 
#  select(Persistente, Precarizado, Transitório)
#urbanidade_2
```

O maior grau de urbanização estão entre os TCP's persistentes, e o de ruralização, nos de precarizados.

```{r}
sub_design <- subset(design, cluster %in% c("Persistente", "Transitório"))

sub_design$variables$V1022 <- ifelse(sub_design$variables$V1022 == "Urbana", 1, 0)

svychisq(~V1022 + cluster, sub_design, statistic = "F")
```

### 1.5.4. Quantidade de pessoas no domicílio

```{r}

descritivo_qtd_pessoas <- svyby(~pessoas_domicilio, ~cluster, design, svymean, na.rm = TRUE) |> 
  select(-se)

descritivo_qtd_pessoas
```

Os precarizados estão inseridos em domicílios mais habitados, e o persistentes, nos menos habitados.

### 1.5.5. Posicão familiar

```{r}

descritivo_chefe_familia <- svyby(~chefe_domicilio, ~cluster, design, svymean) |> 
  select(1:3)

sub_design <- subset(design, cluster %in% c("Precarizado", "Transitório"))

sub_design$variables$chefe_domicilio <- ifelse(sub_design$variables$chefe_domicilio == "Responsável pelo domicílio", 1, 0)

svychisq(~chefe_domicilio + cluster, sub_design, statistic = "F")

descritivo_chefe_familia
```

Observe que os persistentes têm percentual consideralmente maior de responsáveis pelo domicílio do que os demais clusters. A diferença entre os transitórios e precarizados parece não ser significativa.

### 1.5.6. Gênero

```{r}
descritivo_genero <- svyby(~V2007, ~cluster, design, svymean) |> 
  select(1:3)

descritivo_genero
```

A proporção de homens é majoritária nos clustes de transitórios e persistentes, e as mulheres no de precarizados.

### 1.5.5. Idade

```{r}

descritivo_idade <- svyby(~V2009, ~cluster, design, svymean, na.rm = TRUE)

descritivo_idade_mediana <- svyby(
     ~V2009, 
     ~cluster, 
     design, 
     svyquantile, 
     quantiles = 0.5, 
     ci = TRUE,
     na.rm = TRUE,
     keep.var = TRUE)

descritivo_idade
```

Os persistentes são os mais velhos, enquanto os transitórios são os mais jovens.

### 1.5.7. Escolaridade

```{r}
descritivo_escolaridade <- svyby(~ensino_superior, ~cluster, design, svymean) |> 
  select(1:3)

sub_design <- subset(design, cluster %in% c("Persistente", "Transitório"))

sub_design$variables$V1022 <- ifelse(sub_design$variables$ensino_superior == "Superior completo", 1, 0)

svychisq(~ensino_superior + cluster, sub_design, statistic = "F")

descritivo_escolaridade
```

Os precarizados têm o menor grau de pessoas com ensino superior. Enquanto, a diferença entre os transitórios e persistentes parece ser não significativa.

### 1.5.6. Raça

```{r}
descritivo_raca <- svyby(~V2010, ~cluster, design, svymean) |> 
  select(1:6)
```

Considerando as três principais raças, as maiores proporções de clusters são:

-   Brancos: Persistentes;

-   Pardos: Pracarizados;

-   Pretos: Transitórios.

### 1.5.9. Atividade profissional

Analisar quais setores são mais frequentes em cada padrão de carreira tem um nível de complexidade em que as funções do `survey` não conseguem suprir. É preciso considerar que um TCP, durante as cinco entrevistas, podem mudar de atividade. E portanto, é preciso ponderar cada unidade do tempo. Então, a seguir, analisaremos quais setores mais frequentes para cada cluster na condição de TCP. Utilizaremos as funções do `tidyverse` considerando os pesos populacionais.

```{r}

descritivo_atividade <- dados_tratados |> 
  filter(id %in% dados_cluster$id) |> 
  select(id, ocupacao, V1016, VD4010, V1028) |> 
  left_join(id_cluster, by = "id") |> 
  filter(ocupacao == "TCP") |> 
  group_by(cluster, VD4010) |> 
  summarise(freq = sum(V1028), .groups = "drop") |> 
  group_by(cluster) |> 
  mutate(prop = freq / sum(freq)) |> 
  arrange(cluster, desc(freq)) |> 
  select(-freq) |> 
  pivot_wider(names_from = cluster, values_from = prop)

descritivo_atividade

write_xlsx(descritivo_atividade, "tabela_atividades.xlsx")
```

Os resultados mostram que os dois setores mais frequentes daqueles que exercem o trabalho por conta própria de forma persistente é o comércio, reparação de veículos automotores e motocicletas (18%) e outros serviços (15%).

No caso dos indivíduos caracterizados por períodos no desemprego/inatividade, quando ocupados no trabalho autônomo, exercem com maior frequência nos setores comércio, reparação de veículos automotores e motocicletas (23%) e Agricultura, pecuária, produção florestal, pesca e aquicultura (17%).

E por fim, no caso dos indivíduos que transitam entre o emprego no setor privado e o trabalho por conta própria, exercem com maior frequência no setor de Construção (18%) e Informação, comunicação e atividades financeiras, imobiliárias, profissionais e administrativas (16%).

```{r}
descritivo_atividade_long <- descritivo_atividade |> 
  pivot_longer(cols = 2:4,
               names_to = "Cluster",
               values_to = "Proporcao") |> 
  mutate(Cluster = recode(Cluster,
                            "Precarizado" = "Necessidade",
                            "Transitório" = "Intermitente")) |> 
  filter(VD4010 != "Atividades mal definidas")

grafico_atividade <- descritivo_atividade_long %>%
  group_by(VD4010) %>%
  mutate(total = sum(Proporcao)) %>%
  ungroup() %>%
  mutate(
    VD4010 = fct_reorder(VD4010, -total, .desc = TRUE),              # ordem maior -> menor
    VD4010 = fct_relabel(VD4010, ~ str_wrap(.x, width = 40))       # quebra sem perder a ordem
  ) %>%
  ggplot(aes(x = VD4010, y = Proporcao, fill = Cluster)) +
  geom_bar(stat = "identity", position = "stack", width = 0.8,
           color = "white", alpha = 0.95) +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = NULL, y = NULL, fill = NULL) +
  scale_fill_manual(values = c("Persistente" = "#33A02C",
                               "Necessidade"  = "#E34A33",
                               "Intermitente" = "#FDBF00")) +
  theme_minimal() +
  guides(fill = guide_legend(reverse = TRUE)) +
  geom_text(aes(label = scales::percent(Proporcao, accuracy = 1)),   # rótulo percentual
            position = position_stack(vjust = 0.5), 
            size = 3.5, color = "white") +
  theme(axis.text.y = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.position = "top")

ggsave(plot = grafico_atividade, filename = "grafico_atividade.png", height = 1100, width = 1500, units = "px", dpi = 150)
```

### 1.5.10. Renda média

```{r}

descritivo_renda <- svyby(~renda_media, ~cluster, design, svymean, na.rm = TRUE)


sub_design <- subset(design, cluster %in% c("Persistente", "Transitório"))

sub_design$variables$renda_media <- ifelse(sub_design$variables$ensino_superior == "Superior completo", 1, 0)

svyttest(renda_media ~ cluster, sub_design)
```

#### 1.5.10.1. Renda média por região

```{r}
descritivo_renda_regiao <- dados_cluster |> 
  filter(id %in% id_cluster$id) |> 
  filter(ocupacao == "TCP") |> 
  group_by(id, regiao, cluster) |> 
  summarise(renda_media = mean(VD4016)) |> 
  group_by(regiao, cluster) |> 
    summarise(across(renda_media, list(
      media = ~mean(.x, na.rm = TRUE),
      desvio = ~sd(.x, na.rm = TRUE),
      mediana = ~median(.x, na.rm = TRUE),
      minimo = ~min(.x, na.rm = TRUE),
      maximo = ~max(.x, na.rm = TRUE)
    )))


renda_regiao <- svyby(~renda_media, ~cluster + regiao, design, svymean, na.rm = TRUE)
```

## 1.6. Análise exploratória multinomial

```{r}

design$variables$cluster <- factor(design$variables$cluster)
design$variables$cluster <- relevel(design$variables$cluster, ref = "Persistente")

modelo_teste <- multinom(cluster ~ V2007 + V2009 + V1022 + ensino_superior + regiao + chefe_domicilio, data = design$variables)

summary(modelo_teste)
exp(coef(modelo_teste))
```

## 1.7. Correlações

```{r}

taxa_desocupacao <- read_excel("C:/Users/alefs/OneDrive/Documentos/LAPEI-CIGETS/GitHub/tcp/01_dados/desocupacao_tabela4099.xlsx") |> 
  select(-cod_uf)

idh <- read_excel("C:/Users/alefs/OneDrive/Documentos/LAPEI-CIGETS/GitHub/tcp/01_dados/idh.xlsx")

descritivo_uf_2$uf <- rownames(descritivo_uf_2)

tabela_correlacao <- descritivo_uf_2 |> 
  left_join(taxa_desocupacao, by = "uf") |> 
  left_join(idh, by = "uf") |> 
  mutate(
    uf = case_when(
      uf == "Acre" ~ "AC",
      uf == "Alagoas" ~ "AL",
      uf == "Amapá" ~ "AP",
      uf == "Amazonas" ~ "AM",
      uf == "Bahia" ~ "BA",
      uf == "Ceará" ~ "CE",
      uf == "Distrito Federal" ~ "DF",
      uf == "Espírito Santo" ~ "ES",
      uf == "Goiás" ~ "GO",
      uf == "Maranhão" ~ "MA",
      uf == "Mato Grosso" ~ "MT",
      uf == "Mato Grosso do Sul" ~ "MS",
      uf == "Minas Gerais" ~ "MG",
      uf == "Pará" ~ "PA",
      uf == "Paraíba" ~ "PB",
      uf == "Paraná" ~ "PR",
      uf == "Pernambuco" ~ "PE",
      uf == "Piauí" ~ "PI",
      uf == "Rio de Janeiro" ~ "RJ",
      uf == "Rio Grande do Norte" ~ "RN",
      uf == "Rio Grande do Sul" ~ "RS",
      uf == "Rondônia" ~ "RO",
      uf == "Roraima" ~ "RR",
      uf == "Santa Catarina" ~ "SC",
      uf == "São Paulo" ~ "SP",
      uf == "Sergipe" ~ "SE",
      uf == "Tocantins" ~ "TO",
    ),
    regiao = case_when(
      uf %in% c("AC","AP","AM","PA","RO","RR","TO") ~ "Norte",
      uf %in% c("AL","BA","CE","MA","PB","PE","PI","RN","SE") ~
        "Nordeste",
      uf %in% c("DF","GO","MT","MS") ~ "Centro-Oeste",
      uf %in% c("ES","MG","RJ","SP") ~ "Sudeste",
      uf %in% c("PR","RS","SC") ~ "Sul"
  ))

test_correlacao <- cor.test(tabela_correlacao$IDHM,
                            tabela_correlacao$Precarizado,
                            alternative = "less",
                            method = "kendall")
test_correlacao

r <- round(test_correlacao$estimate, 3)
p_value <- test_correlacao$p.value
p_text <- ifelse(p_value < 0.01, "p < 0.01", paste("p =", round(p_value, 3)))

grafico_correlacao <- tabela_correlacao |> 
  ggplot(aes(x = IDHM, y = Precarizado)) +
  geom_point() +
  geom_label(aes(label = uf, fill = regiao)) +
  labs(fill = "") +
  geom_smooth(method = "lm", se =  FALSE) +
  theme_minimal() +
  xlab("Índice de Desenvolvimento Humano (IDH)") +
  ylab("Percentual de TCP por necesidade") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(
    text = element_text(size = 16),          
    axis.title = element_text(size = 14),    
    axis.text = element_text(size = 14),     
    legend.title = element_text(size = 16),  
    legend.text = element_text(size = 14),
    legend.position = "bottom"
  ) +
  annotate("text", x = 0.78, y = 0.4, 
           label = paste("r =", r, ",", p_text),
           size = 6, hjust = 1)


#ggsave(grafico_correlacao, filename = "grafico_correlacao.png", height = 1100, width = 1500, units = "px", dpi = 150)
```
